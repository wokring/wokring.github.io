# Question 3 - GPU Performance
One way to check the GPU performance is to measure the change in training time of the model by varying the batch size. The batch sizes that were tested were: 16, 32, 64, 128, 256.

The batch size can be changed by changing the optional argument `bs` in `DataBlock.dataloaders()` method from *fastai*.

```python
dls = DataBlock(...).dataloaders(path, bs=?)
```

Here are the results of the GPU load from various batch sizes using **nvtop**.

![](/images/batch16.png "Batch Size of 16")
*Batch Size of 16*

![](/images/batch32.png "Batch Size of 32")
*Batch Size of 32*

![](/images/batch64.png "Batch Size of 64")
*Batch Size of 64*

![](/images/batch128.png "Batch Size of 128")
*Batch Size of 128*

![](/images/batch256.png "Batch Size of 256")
*Batch Size of 256*
